{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "train_dir = r'E:\\Tensorflow\\decision_tree\\ChestXRay2017\\chest_xray\\train'\n",
    "validation_dir = r'E:\\Tensorflow\\decision_tree\\ChestXRay2017\\chest_xray\\test'\n",
    "# Directory with our training horse pictures\n",
    "train_PNEUMONIA_dir = os.path.join(r'E:\\Tensorflow\\decision_tree\\ChestXRay2017\\chest_xray\\train\\PNEUMONIA')\n",
    "\n",
    "# Directory with our training human pictures\n",
    "train_NORMAL_dir = os.path.join(r'E:\\Tensorflow\\decision_tree\\ChestXRay2017\\chest_xray\\train\\NORMAL')\n",
    "\n",
    "train_PNEUMONIA_names = os.listdir(train_PNEUMONIA_dir)\n",
    "print(train_PNEUMONIA_names[:10])\n",
    "\n",
    "train_NORMAL_names = os.listdir(train_NORMAL_dir)\n",
    "print(train_NORMAL_names[:10])\n",
    "\n",
    "print('total training PNEUMONIA images:', len(os.listdir(train_PNEUMONIA_dir)))\n",
    "print('total training NORMAL images:', len(os.listdir(train_NORMAL_dir)))\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "\n",
    "\n",
    "# Parameters for our graph; we'll output images in a 4x4 configuration\n",
    "nrows = 4\n",
    "ncols = 4\n",
    "\n",
    "# Index for iterating over images\n",
    "pic_index = 0\n",
    "\n",
    "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(ncols * 4, nrows * 4)\n",
    "\n",
    "pic_index += 8\n",
    "next_PNEUMONIA_pix = [os.path.join(train_PNEUMONIA_dir, fname) \n",
    "                for fname in train_PNEUMONIA_names[pic_index-8:pic_index]]\n",
    "next_NORMAL_pix = [os.path.join(train_NORMAL_dir, fname) \n",
    "                for fname in train_NORMAL_names[pic_index-8:pic_index]]\n",
    "\n",
    "for i, img_path in enumerate(next_PNEUMONIA_pix+next_NORMAL_pix):\n",
    "\n",
    "  # Set up subplot; subplot indices start at 1\n",
    "    sp = plt.subplot(nrows, ncols, i + 1)\n",
    "    sp.axis('Off') # Don't show axes (or gridlines)\n",
    "\n",
    "    img = mpimg.imread(img_path)\n",
    "    plt.imshow(img)\n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "model = tf.keras.models.Sequential([\n",
    "    # Note the input shape is the desired size of the image 300x300 with 3 bytes color\n",
    "    # This is the first convolution\n",
    "    tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(200, 200, 3)),\n",
    "    tf.keras.layers.MaxPooling2D(2, 2),\n",
    "    # The second convolution\n",
    "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The third convolution\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fourth convolution\n",
    "    tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
    "    tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # The fifth convolution\n",
    "    #tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
    "    #tf.keras.layers.MaxPooling2D(2,2),\n",
    "    # Flatten the results to feed into a DNN\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dropout(0.5),\n",
    "    # 512 neuron hidden layer\n",
    "    tf.keras.layers.Dense(512, activation='relu'),\n",
    "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n",
    "\n",
    "# All images will be rescaled by 1./255\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255.,\n",
    "                                   rotation_range=40,\n",
    "                                   width_shift_range = 0.2,\n",
    "                                   height_shift_range = 0.2,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True)\n",
    "\n",
    "# Flow training images in batches of 128 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "        train_dir,  # This is the source directory for training images\n",
    "        target_size=(200, 200),  # All images will be resized to 150x150\n",
    "        batch_size=96,\n",
    "        # Since we use binary_crossentropy loss, we need binary labels\n",
    "        class_mode='binary')\n",
    "\n",
    "test_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
    "\n",
    "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
    "                                                         batch_size  = 32,\n",
    "                                                         class_mode  = 'binary', \n",
    "                                                         target_size = (200, 200))\n",
    "\n",
    "history = model.fit(train_generator,\n",
    "                    steps_per_epoch=10,  \n",
    "                    epochs=75,\n",
    "                    validation_data = validation_generator,\n",
    "                    validation_steps = 8,\n",
    "                    verbose=1)\n",
    "\n",
    "model.save(\"single_layer_model_95%.h5\")\n",
    "print(\"Saved model to disk\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.]\n",
      "input image is infected\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "model = tf.keras.models.load_model('single_layer_model_95%.h5')\n",
    "\n",
    "\n",
    "path=r'E:\\Tensorflow\\decision_tree\\ChestXRay2017\\chest_xray\\test\\NORMAL\\NORMAL2-IM-0060-0001.jpeg'\n",
    "\n",
    "img=image.load_img(path, target_size=(200, 200))\n",
    "x=image.img_to_array(img)\n",
    "x=np.expand_dims(x, axis=0)\n",
    "images = np.vstack([x])\n",
    "classes = model.predict(images, batch_size=32)\n",
    "print(classes[0])\n",
    "if classes[0]>0.5:\n",
    "    print(\"input image is normal\")    \n",
    "else:\n",
    "    print(\"input image is infected\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflowgpu",
   "language": "python",
   "name": "tensorflowgpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
